{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I2T and T2I search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os.path as op\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from pycocotools.coco import COCO\n",
    "import seaborn as sns\n",
    "\n",
    "from retrieval_pipelines import absolute_coco_path, tag_to_image_search, image_to_tag_search, most_common_tags\n",
    "from text_processing import create_caption_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coco API loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_dir = \"dataset\"\n",
    "data_type = \"train2014\"\n",
    "ann_file = op.join(\n",
    "    data_dir, \"annotations\", \"instances_{0}.json\".format(data_type))\n",
    "coco = COCO(ann_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-calculated features loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_visual = np.load(\"W1.npy\")\n",
    "W_text = np.load(\"W2.npy\")\n",
    "V = np.load(\"V.npy\")\n",
    "T = np.load(\"T.npy\")\n",
    "img_ids = np.load(\"visual_img_ids.npy\")\n",
    "W_text = W_text.T\n",
    "W_visual = W_visual.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tag to image search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "database_images = W_visual.dot(V.T)\n",
    "database_images = database_images.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tag = \"giraffe\"\n",
    "feature_path = \"{0}_features.npy\".format(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not op.exists(feature_path):\n",
    "    import gensim\n",
    "    \n",
    "    from text_processing import sentence2vec\n",
    "    \n",
    "    print('\\nLoading word2vec model ...')\n",
    "    model_path = op.join('models', 'GoogleNews-vectors-negative300.bin')\n",
    "    model = gensim.models.Word2Vec.load_word2vec_format(model_path, binary=True)\n",
    "    tag_features = sentence2vec(tag, model)\n",
    "    del model\n",
    "    np.save(\"{0}_features\".format(tag), tag_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tag_features = np.load(feature_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "retrieved_img_ids = tag_to_image_search(tag_features, W_text, database_images, img_ids, coco, n_images=10)\n",
    "img_paths = [absolute_coco_path(int(img_id), coco) for img_id in retrieved_img_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"dark\")\n",
    "for im_idx, img_path in enumerate(img_paths):\n",
    "    plt.figure(im_idx)\n",
    "    img = mpimg.imread(img_path)\n",
    "    imgplot = plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image to tag search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "database_captions = W_text.dot(T.T)\n",
    "database_captions = database_captions.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_name = \"giraffe.jpg\"\n",
    "image_path = op.join(data_dir, \"test\", image_name)\n",
    "visual_feature_path = \"{0}_visual_features.npy\".format(image_name.split(\".\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(mpimg.imread(image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not op.exists(visual_feature_path):\n",
    "    from keras.applications import vgg19\n",
    "    from keras.optimizers import SGD\n",
    "    \n",
    "    from image_processing import process_image\n",
    "    from vgg import compute_nn_features\n",
    "    \n",
    "    img_mat = process_image(image_path)\n",
    "    net = vgg19.VGG19()\n",
    "    sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    net.compile(optimizer=sgd, loss='categorical_crossentropy')\n",
    "    visual_features = compute_nn_features([img_mat], net)\n",
    "    np.save(\"{0}_visual_features\".format(image_name.split(\".\")[0]), visual_features)\n",
    "    del net\n",
    "    del sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visual_features = np.load(visual_feature_path)\n",
    "visual_features = np.reshape(visual_features, (W_visual.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_tags = 4\n",
    "annotations = image_to_tag_search(visual_features.T, W_visual, database_captions, img_ids, coco, n_tags=n_tags, expanding_factor=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stops = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "most_common_tags(annotations, n_tags, stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_id = retrieved_img_ids[0]\n",
    "coco.loadImgs(int(img_id))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision recall (PR) curve for T2I\n",
    "Given that the caption evaluation is not available in the Python MS Coco API, we chose to check whether an image was correctly returned by seeing if the tag was present in the description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_caption = create_caption_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tags = \"giraffe snowboard boat snow water\".split()\n",
    "features_paths = [\"{0}_features.npy\".format(tag) for tag in tags]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do a pre-processing of all the tags in order not to have to run the forward pass everytime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for tag_idx, tag in enumerate(tags):\n",
    "    import gensim\n",
    "    from text_processing import sentence2vec\n",
    "    if not op.exists(features_paths[tag_idx]):\n",
    "        try:\n",
    "            model\n",
    "        except NameError:\n",
    "            print(\"Loading Word2Vec model\")\n",
    "            model_path = op.join('models', 'GoogleNews-vectors-negative300.bin')\n",
    "            model = gensim.models.Word2Vec.load_word2vec_format(model_path, binary=True)\n",
    "        finally:\n",
    "            tag_features = sentence2vec(tag, model)\n",
    "            np.save(\"{0}_features\".format(tag), tag_features)\n",
    "            del tag_features\n",
    "try:\n",
    "    del model\n",
    "except NameError:\n",
    "    print(\"its all good man\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the recall, we need to first compute the number of images for this tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counter = dict()\n",
    "for tag in tags:\n",
    "    counter[tag] = 0\n",
    "for caption in df_caption[\"caption\"]:\n",
    "    for tag in tags:\n",
    "        counter[tag] += int(tag in caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_n_images = 1000\n",
    "precisions = dict()\n",
    "recalls = dict()\n",
    "for tag in tags:\n",
    "    precisions[tag] = np.zeros(max_n_images)\n",
    "    recalls[tag] = np.zeros(max_n_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for tag_idx, tag in enumerate(tags):\n",
    "    tag_features = np.load(features_paths[tag_idx])\n",
    "    for n_images in range(1, max_n_images+1):\n",
    "        retrieved_img_ids = tag_to_image_search(tag_features, W_text, database_images, img_ids, coco, n_images=n_images)\n",
    "        correct_number = 0\n",
    "        for caption in df_caption.loc[retrieved_img_ids][\"caption\"]:\n",
    "            correct_number += int(tag in caption)\n",
    "        precisions[tag][n_images - 1] = correct_number*100 / n_images\n",
    "        recalls[tag][n_images - 1] = correct_number*100 / counter[tag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "for tag_idx, tag in enumerate(tags):\n",
    "    precision = precisions[tag]\n",
    "    recall = recalls[tag]\n",
    "    plt.figure(tag_idx)\n",
    "    plt.title(\"Precision-Recall curve for {0}\".format(tag))\n",
    "    plt.plot(recall, precision, label=\"PR\")\n",
    "    plt.ylabel(\"Precision (%)\")\n",
    "    plt.xlabel(\"Recall (%)\")\n",
    "    plt.legend(loc=4)\n",
    "    plt.axis([0, 50, 0, 100])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
